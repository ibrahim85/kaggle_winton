{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test our algorithm for guessing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def test_missing_values_guess(N_OBS,N_FEATURES):\n",
    "\"\"\"\n",
    "hello!\n",
    "This is a script that tests our algorithm for imputing missing values (NAs). I\n",
    "generate data from distributions where the Features\n",
    "have some relationship to each other (such as multivariate normal), which makes\n",
    "it worthwhile to do something more intelligent than just using the mean value\n",
    "for each Feature.\n",
    "\n",
    "Steps:\n",
    "1. Create distribution (for multivariate normal, create means & covariances)\n",
    "2. Generate data from that distribution\n",
    "3. Convert a randomly selected subset of the data to NAs\n",
    "4. Apply the algorithm to impute the NAs\n",
    "5. Calculate how close the algorithm got to the true values\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How big a dataset do we want to test on\n",
    "N_OBS = 100;\n",
    "N_FEATURES = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test case 1: Multivariate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Case 1: Single Multivariate Normal distribution\n",
    "# randomly generate correlation matrix for the distribution. All correlations must\n",
    "# be between -1 and 1. 'random' uses the uniform distribution.\n",
    "C = np.random.random((N_FEATURES,N_FEATURES))*2. - 1.\n",
    "for i in range(N_FEATURES):\n",
    "    C[i,i] = 1.\n",
    "# randomly generate volatilities. All volatilities must be positive.\n",
    "v = np.random.rand(N_FEATURES,1)*10.\n",
    "# covariance matrix. Convolve volatilites and correlations. (v*v').*(C)\n",
    "V = np.dot(v,v.T)\n",
    "# alternative way:\n",
    "V = np.outer(v,v)\n",
    "cov = V * C\n",
    "# ensure symmetry\n",
    "cov = (cov + cov.T)/2.\n",
    "# randomly generate means\n",
    "mu = np.random.rand(N_FEATURES,)*2. - 1.\n",
    "# randomly generate data\n",
    "data = np.random.multivariate_normal(mu,cov,N_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose random fraction of data to convert to NAs\n",
    "NA_FRACTION = 0.19\n",
    "\n",
    "# create copy of data. This copy will have data converted to NAs\n",
    "datan = data.copy()\n",
    "# create a random index for the subsample that will be created to NAs\n",
    "random_index = sorted(random.sample(range(datan.size),int(math.floor(datan.size*NA_FRACTION))))\n",
    "# heres a better way to do it! convert to 1D array, convert subset of data\n",
    "# randomly selected by the index to NA, then return to original shape\n",
    "datan.shape = (N_OBS*N_FEATURES,)\n",
    "datan[random_index] = np.nan\n",
    "datan.shape = (N_OBS,N_FEATURES)\n",
    "np.isnan(datan).sum() / np.size(datan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guess the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply algorithm to compute NAs\n",
    "# !!! this is your code !!\n",
    "# data_imputed = impute_NAs_using_KNN(datan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the RMSE of the guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RMSE of difference between imputed and original data\n",
    "# rmse_guess = np.sqrt(((data_imputed[np.isnan(datan)] - data[np.isnan(datan)])**2).sum())\n",
    "rmse_zero = np.sqrt(((np.zeros_like(data[np.isnan(datan)]) - data[np.isnan(datan)])**2).sum())\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.86381906995\n"
     ]
    }
   ],
   "source": [
    "print rmse_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat many times to get a statistical picture of the method's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
