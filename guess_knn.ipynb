{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "#import urllib, requests, zipfile, StringIO\n",
    "#import numpy, scipy\n",
    "#import matplotlib.pyplot as plt\n",
    "#import mlpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from time import time\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#from pylab import *\n",
    "#import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "# import the training data as a \"data frame\"\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "features=train.ix[:,'Feature_1':'Feature_25']\n",
    "train_=train.dropna()\n",
    "#test  = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# heatmap of correlations\n",
    "feature_corr = train.ix[:,'Feature_1':'Feature_25'].corr()\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "features.isnull().sum()\n",
    "null_data = features[features.isnull().any(axis=1)]\n",
    "null_data.head()\n",
    "null_data['nans']=null_data.apply(lambda x: sum(x.isnull().values), axis = 1)\n",
    "null_data.head()\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "#features['Feature_1'].dropna()\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "train_.info()\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "# split the data into X and Y\n",
    "# note that Y is more than one variable\n",
    "# ignore the last two variables, 'Weight_Intraday' and 'Weight_Daily'. We dont know what to do with them yet.\n",
    "# We use them only in the scoring function.\n",
    "X = train_.ix[:,'Feature_1':'Ret_120']\n",
    "Y = train_.ix[:,'Ret_121':'Ret_PlusTwo']\n",
    "#print X, Y\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "# Create an Extremely-Randomized-Trees regressor\n",
    "extra = ExtraTreesRegressor(n_estimators=100, criterion='mse', max_depth=None, min_samples_split=1, bootstrap=False, n_jobs=-1)\n",
    "t0=time()\n",
    "extra = extra.fit(X,Y)\n",
    "t1=time()\n",
    "print \"time elapsed %.2f seconds\" % (t1-t0)\n",
    "fi=pd.DataFrame(extra.feature_importances_,index=X.columns.values,columns=['importance'])\n",
    "# fi.head(10)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "#fi=zip(X.columns.values, extra.feature_importances_)\n",
    "#type(extra.feature_importances_)\n",
    "#fi.sort_values(by='importance', ascending=False,inplace=True)\n",
    "#fi.plot(kind='bar')\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "'''\n",
    "this will be the function that replaces missing data by KNN'''\n",
    "def knn_imputation(df):\n",
    "    df['nans']=df.apply(lambda x: sum(x.isnull().values), axis = 1)\n",
    "    df.sort_values(by='nans', ascending=True, inplace=True)\n",
    "    all_data=df[df['nans']==0]\n",
    "    #null_data = df[df.isnull().any(axis=1)]\n",
    "    null_data=df[df['nans']!=0]\n",
    "    #replace missing values for rows with one variable by knn\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# In[187]:\n",
    "\n",
    "'''\n",
    "replacing NaNs by KNN. There are many missing values in different columns and rows. Start with a row, let's say row,\n",
    "with one missing value in column col; then take the Y to be df[0:row-1,col] and X df[0:row-1, all columns except col].\n",
    "run KNN for X, Y. predict df[row,col]. fill it in. add to the complete data.'''\n",
    "\n",
    "# null_data = features[features.isnull().any(axis=1)]\n",
    "# null_data.head()\n",
    "# null_data['nans']=null_data.apply(lambda x: sum(x.isnull().values), axis = 1)\n",
    "df=train.ix[:,'Feature_1':'Feature_25'] #keep only the features in df\n",
    "#df['nans']=df.apply(lambda x: sum(x.isnull().values), axis = 1) #create a column that counts number of NaNs by row\n",
    "df['nans']=df.apply(lambda x: len(x)-x.count(), axis = 1) #create a column that counts number of NaNs by row\n",
    "df.sort_values(by='nans', ascending=True, inplace=True)#sort by nr of NaNs. complete cases will be at the top\n",
    "df=df.reset_index(drop=True) #reset the index after sorting matrix\n",
    "clean_data=df[df['nans']==0] #not sure if I'll use this\n",
    "#null_data = df[df.isnull().any(axis=1)]\n",
    "#null_data=df[df['nans']!=0]\n",
    "rows_complete=len(df[df.nans==0])\n",
    "i=0\n",
    "print df.iloc[rows_complete+1:rows_complete+6,:]\n",
    "#replace missing values for rows with one variable by knn, have to do it one by one\n",
    "for row in range(rows_complete,len(df)): #each row in the set of rows that only have one missing value\n",
    "        if i<10:\n",
    "            '''code below only works for one missing value currently; should loop through all missing values'''\n",
    "            col_nan=np.where(df.iloc[row,:].isnull())[0] #gives me the column with NaN for each row --- there's only one to begin with\n",
    "            print (\"working on row \", row, \" NaN in column \",df.columns[col_nan])\n",
    "            data=df.iloc[:row,:]\n",
    "            data=data.drop(df.columns[col_nan],1)#pick the data frame with complete cases, dropping the column where row has the missing value\n",
    "            X_na=data.tail(1)\n",
    "            X=data.iloc[:-1,:]\n",
    "            Y=df.iloc[:row-1,col_nan]\n",
    "            myknn = KNeighborsRegressor(n_neighbors=3,weights='distance') \n",
    "            myknn.fit(X, Y) #fit KNN to the complete data\n",
    "            df.iloc[row,col_nan]=myknn.predict(X_na)[0][0] #predict the missing value\n",
    "            print df.iloc[rows_complete:rows_complete+6,:] \n",
    "        i=i+1\n",
    "\n",
    "\n",
    "# In[178]:\n",
    "\n",
    "print data.iloc[:-1,:].shape\n",
    "print myknn.predict(X_na).ravel()[0]\n",
    "\n",
    "\n",
    "# In[133]:\n",
    "\n",
    "x=[[1,2,3],[np.NaN,4,np.NaN]]\n",
    "df=pd.DataFrame(x,columns=['A','B','C'])\n",
    "print df\n",
    "n=np.where(df.iloc[1,:].isnull())\n",
    "print (n)\n",
    "print (n[0])\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "print len(df[df.nans==5])\n",
    "print df.nans[39000]\n",
    "# n=df.columns[df.isnull().any()].tolist()\n",
    "# v=df.apply(lambda x: )\n",
    "\n",
    "#df.iloc[:,np.where(df.iloc[1,:].isnull())[0]]\n",
    "#print df.columns[df.loc[1,:].isnull()]\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "df.columns[df.loc[39093,:].isnull().any()]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "sum(df.loc[1,].isnull())\n",
    "df.loc[1294,]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "len(df.loc[1,])-df.loc[1,].count()\n",
    "\n",
    "\n",
    "# In[130]:\n",
    "\n",
    "X=df.loc[:row-1,:]\n",
    "X=X.drop('Feature_1',axis=1)\n",
    "X.head()\n",
    "\n",
    "\n",
    "# In[151]:\n",
    "\n",
    "print col_nan\n",
    "print np.where(df.iloc[row,:].isnull())\n",
    "print row\n",
    "print df.loc[row,:]\n",
    "print df.iloc[1293,0]\n",
    "print myknn.predict(X_na)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
